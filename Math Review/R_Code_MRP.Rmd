---
title: "R Code to Complement Math Review Packet"
output:
  pdf_document: null
  html_document:
    df_print: paged
  toc: yes
  toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### A Note:
The notes and code in this document are meant to serve as complementary material to the Math Review Packet. In this program you will be able to perform many calculations in R, which provides more flexibility and data storage than a typical calculator. The R code below is meant to a) introduce you to using R as a calculator and b) give some context for how you could use R to solve a variety of problems. 

We will cover: \newline
- Logarithms \newline
- Matrices \newline
- Statistical concepts \newline
    * Central tendency \newline  
    * The Central Limit Theorem \newline  
    * Covariance and correlation \newline  
    * Ordinary Least Square regression \newline  

Please use this as a resource to become more comofortable with R. You can run the R chunks by pressing the green play button in the top right corner (of the chunk). Or, you can run parts of the code and change portions of it in the Console. It may also be useful to look up functions in the **Help** tab (or type '?function' into the Console) to see function documentation. 

You may also find it helpful to take notes in this document so that you can reference it during the first few months of classes. You can comment (by using '#' in the R chunk) as a way of annotating it in your own words. This is good practice for deciphering other people's code and is a good habit for documenting your own future work. 

Note: In this document, you will also see LaTeX notation, which is used to render math symbols when you knit to PDF. If you hover over the items in the dollar signs, you will see what the formatting will look like when knitted to a PDF. 

\pagebreak

## Properties of Logarithms

In R, the log() function computes natural logarithms (i.e., $ln()$). To calculate $log_{10}()$ use log10(); to calculate $log_{2}()$, use log2().  

For example if we wanted to solve $log_{10}(10000)$: 
```{r log10}
log10(10000)
```

In general, we can also calculate exponents using the ^ character. For example, $3^8$ could be calculated by typing 3^8. Additionally, if we wanted to calculate $e^4$, we could use the exp() function.  
```{r exp}
3^8
exp(4)
```

### Practice Problems.
1. Show that, if x=3, it is true that:
a. $log_e(e^x) = x$
```{r Logs 1a}
log(exp(3))
```

b. $log_{10}(100)$
```{r Logs 1b}
log10(10)
```

c. $log_{10}(\frac{1}{10})$
```{r Logs 1c}
log10(1/100)
```

d. $log_{10}(0)$ Note: There is no solution here; R returns -Inf  
```{r Logs 1d}
log10(0)
```
  

\pagebreak

# Matrix Algebra

### Creating a Matrix in R 
Type ?matrix in the **Console** or matrix in **Help** to look at the inputs of the matrix function.  
  
When you look at the usage of a function, you may see that some parameters are assigned default values, while others are assigned "NA" or "NULL" values (i.e., missing values). In the matrix function, we need to input a vector of values, the number of rows, number of columns, an indication of whether the matrix should be filled by row-wise (or column-wise), and dimension names if we want them. Note that, if we do not indicate a number of rows, the matrix will automatically have one row. Also note that, by default, the matrix will be filled column-wise (you can change the byrow parameter to TRUE to fill the matrix row-wise).    
If we want to store the matrix for future use, we need give a name to the matrix ("Z", for example), and use an arrow (<-) or equals sign (=) to assign the result of the matrix function to that name. We can also use the print() function to print the matrices we have created.   

For example $\textbf{Z} = \begin{bmatrix} 1&2&3\\ 4&5&6\\ 7&8&9\\ \end{bmatrix}$ $\textbf{Y} = \begin{bmatrix} 1&4&7\\ 2&5&8\\ 3&6&9\\ \end{bmatrix}$

```{r Matrix Example}
#Sorting by row
Z <- matrix(data = c(1,2,3,4,5,6,7,8,9),nrow = 3, ncol = 3, byrow = TRUE)
print(Z)

#Sorting by column
Y <- matrix(data = (1:9), nrow = 3, ncol = 3, byrow = FALSE)
print(Y)
```

### Definitions 
The transpose of an $m\times n$ matrix, $A$ is the $n\times m$ matrix (denoted $A^T$) such that every element $a_{ij}$ in matrix A is moved to row $j$ and column $i$. For example, if:  
$$\textbf{A}=\begin{bmatrix} 1&2&5\\ 3&4&7\\ \end{bmatrix}$$  
then,  
$$\textbf{A}^T=\begin{bmatrix} 1&3\\ 2&4\\ 5&7\\ \end{bmatrix}$$  
  
In R, we can get the transpose of a matrix by using the t() function
```{r}
# Matrix A
A <- matrix(data = c(1,2,5,3,4,7), nrow = 2, ncol = 3, byrow = TRUE)

print(A)

# A transpose
t(A)
```

#### Identity Matrix 
```{r}
# Identity Matrix: use diag() to create an identity matrix
# I = 4x4 identity matrix
I <- diag(4)
print(I)
class(I) #tells you the object class; in this case, a matrix!
```

#### Diagonal 
```{r}
X1 <- matrix(data = c(1,0,0,0,4,0,0,0,5), nrow = 3, byrow = TRUE)
print(X1)

# To obtain the obtain the values of the diagonal of an n x n matrix
diag(X1)

# We could also create an empty matrix and assign values to the diagonal
X2 <- matrix(data = 0, nrow = 3, ncol = 3)
diag(X2) <- c(1,2,3)
print(X2)
```

#### Upper and Lower Triangular Matrices 
```{r, tidy=TRUE}
# Create a 3 by 3 matrix of zeros
V <- W <- matrix(data = 0, nrow = 3, ncol = 3, byrow = TRUE)
print(W)

# Use upper.tri() or lower.tri() to change the elements of the upper triangular matrix or lower triangular matrix, respectively. 

# Upper Triangular
#this returns a 3 by 3 matrix with TRUE's in the upper triangle and FALSE's everywhere else:
upper.tri(W, diag = TRUE) 
#we can then assign values to the upper triangle of W using square brackets 
W[upper.tri(W, diag = TRUE)] <- c(1:6)
print(W)

# Lower Triangular 
V[lower.tri(V, diag = TRUE)] <- c(1:6)
print(V)
```

#### Inverse of a matrix
```{r}
U <- matrix(data = c(1:4), nrow = 2, byrow = TRUE)
print(U)

# Use the solve() function to obtain the inverse of a matrix
invU <- solve(U)
print(invU)

# We can then perform matrix multiplication using %*%
# Note that, if we just use *, R will multiply the two matrices element-wise, instead of using 
# Matrix multiplication  

# Confirm you get an identity matrix   
result1 <- U %*% invU
result2 <- invU %*% U
round(result1, digits=2)  
round(result2, digits=2)
```

#### Determinant of a matrix
```{r}
# Use det() to obtain the determinant of a matrix
det(U)
```

### Operations with matrices

a. Adding matices
```{r}
# Using the above matrices (Z and Y) we will show that Z + Y = X  
# Note: the dim() function gives the dimensions of a matrix (rows first, then columns)
# Adding matrices of the same dimension will produce a matrix of the same dimension
dim(Z) 
dim(Y)
dim(Z + Y)
Z + Y
```

b. Subtracting matrices
```{r}
# Subtracting matrices of the same dimension will produce a matrix of the same dimension
dim (Z) 
dim(Y)
dim(Z - Y)
Z - Y
```

c. Multiplying a matrix by a scalar
```{r}
# Multiplying a matrix by a scalar will produce a matrix of the same dimension
# Suppose that c = 3

3 * Z 
```

d. Matrix Multiplication
```{r}
m1 <- matrix(data = c(3,4,2,5,1,2), nrow = 3, ncol = 2, byrow = TRUE)
print (m1) ; dim(m1)

m2 <- matrix(data = c(7,2,1,3,5,2), nrow = 2, ncol = 3, byrow = TRUE)
print(m2); dim(m2)

# Matrix multiplication
m1 %*% m2

# It is important to note that when multiplying matrices we need to use %*% rather than * because using * will multiply the values element-wise. 
print(Z); print(Y)
Z * Y 
Z %*% Y
```

### Properties of matrix operations
1. $A + B = B + A$
```{r}
Z + Y
Y + Z
```

2. $(A+B)+C=A+(B+C)$ 
```{r}
(Z + Y) + X1
Z + (Y + X1)
```

3. $(AB)C=A(BC)$
```{r}
(Z %*% Y) %*% X1
Z %*% (Y %*% X1)
```

4. $(A+B)C=AC + BC$ 
```{r}
(Z + Y) %*% X1
(Z %*% X1) + (Y %*% X1)
```

5. If $A$ is an $m\times n$ matrix, then $I_mA=A$ and $AI_n=A$
```{r}
A
Im <- diag(x = 1, nrow = 2)
In <- diag(x = 1, nrow = 3)

Im %*% A
A %*% In
```

Note that, in general $AB \ne BA$   
```{r}
Z %*% Y
Y %*% Z
```
  

\pagebreak  
  
### Practice Problems
1. Show each of the following by solving the left side of the equation in R:    

  a. $\begin{bmatrix} 2&4&2\\ 1&3&0\\1&6&2\\ \end{bmatrix} +
      \begin{bmatrix} 1&5&0\\ -2&-3&0\\ 1&9&5\\ \end{bmatrix} = 
      \begin{bmatrix} 3&9&2\\ -1&0&0\\ 2&15&7\\ \end{bmatrix}$    
        
```{r Matrix 1a}
M1 <- matrix(data = c(2,4,2,1,3,0,1,6,2),
             nrow = 3, ncol = 3, byrow = TRUE)

M2 <- matrix(data = c(1,5,0,-2,-3,0,1,9,5),
             nrow = 3, ncol = 3, byrow = TRUE)

M1 + M2
```

  b. $\begin{bmatrix} 2&1\\ -2&2\\ 4&2\\ \end{bmatrix}
      \begin{bmatrix} 5&2&-1\\ 3&4&2\\ \end{bmatrix} =
      \begin{bmatrix} 13&8&0\\ -4&4&6\\ 26&16&0\\ \end{bmatrix}$  
      
```{r Matrix 1b}
M3 <- matrix(data = c(2,-2,4,1,2,2), nrow = 3, ncol = 2, byrow = FALSE)

M4 <- matrix(data = c(5,3,2,4,-1,2), nrow = 2, ncol = 3, byrow = FALSE)

M3 %*% M4
```

c. Let $\textbf{A} =\begin{bmatrix} 1&2\\ 3&5\\ 4&0\\ \end{bmatrix} \mbox{and } 
       \textbf{B} =\begin{bmatrix} 4&4\\ 1&2\\ 7&0\\ \end{bmatrix}  
       \textbf{A}^T \textbf{B} = \begin{bmatrix} 35&10\\ 13&18\\ \end{bmatrix}$   
       
```{r Matrix 1c}
A <- matrix(data = c(1,2,3,5,4,0), nrow = 3, ncol = 2, byrow = TRUE)

B <- matrix(data = c(4,1,7,4,2,0),nrow = 3, ncol=2, byrow = FALSE)

t(A) %*% B  
```  
  
d. Using the same matrices as in part c, $\textbf{B}^T\textbf{A} = 
\begin{bmatrix} 35&13\\ 10&18\\ \end{bmatrix}$

```{r 1d}
t(B) %*% A
```

Show that **A** and **B** are inverses:  
$\begin{bmatrix} 1&2&1\\ 2&2&0\\ 1&1&1\\ \end{bmatrix}  
  \begin{bmatrix} -1&0.5&1\\ 1&0&-1\\ 0&-0.5&1\\ \end{bmatrix}=
  \begin{bmatrix} 1&0&0\\ 0&1&0\\ 0&0&1\\ \end{bmatrix}$
       
       
```{r Matrix 2}
A <- matrix(data = c(1,2,1,2,2,0,1,1,1), nrow = 3, ncol = 3, byrow = TRUE)

#Use the solve() to find the inverse of a matrix
solve(A)

B <- matrix(data = c(-1, 0.5, 1, 1, 0, -1, 0, -0.5, 1), nrow = 3, ncol = 3, byrow = TRUE)

#Use the solve() to find the inverse of a matrix
solve(B)

A %*% B
```

3. Suppose that $A$ is a 4x3 matrix and $B$ is a $3x8$ matrix.  
```{r Matrix 3}
A <- matrix (data= (1:12), nrow = 4, ncol = 3, byrow = FALSE)
B <- matrix (data = (1:24), nrow = 3, ncol = 8, byrow = TRUE)
```  

  a. $\textbf{AB}$ exists and is 4x8 matrix.   
```{r Matrix 3a}
A %*% B
dim(A%*%B)
```  

  b. $\textbf{BA}$ does not exist.   
```{r Matrix 3b}
# The following produces errors
# B %*% A
```

4. The determinant of $det\begin{bmatrix} 1&-2\\ 4&3\\ \end {bmatrix} = 11$
```{r Matrix 4}
M5 <- matrix(data = c(1, -2, 4, 3), nrow = 2, ncol = 2, byrow = TRUE)
det(M5)
```

\pagebreak   
  
## Variables : Types and Summaries

### Summary statistics for central tendency 
```{r Summary statistics for central tendency, tidy = TRUE}
dat <- c(1,2,3,5,5,4,6,6,1,2,10,11,9,9,9) #save a vector of values

# Mean
mean(dat)

# Median 
median(dat)

# Mode -- R does not have a built in function for mode but you can use the table function to see what the most common value is
table(dat)
as.numeric(names(table(dat))[which.max(table(dat))]) #an ugly hack to find the mode
```

### Summary statistics for spread
```{r Summary statistics for spread}
# Range
#the range function actually returns the minimum and maximum of dat in a vector
range(dat) 

#to calculate the range, we can subtract the first element in range(dat) (the minumum) 
#from the second element in range(dat) (the maximum)
range(dat)[2]-range(dat)[1]

#another option is to use the diff() function, which calculates the difference between to values
diff(range(dat))

# Variance 
var(dat)

# Standard Deviation
sd(dat)

# Show that the square root of the variance gives the same output as sd() 
sqrt(var(dat))
```

\pagebreak
## Central Limit Theorem Introduction
We can sample from many distributions in R. The following will walk through sampling from a normal distribution. 

In the example with average salary of "Data Scientists" we have a sample (n = 400), a mean salary of 100,000 and standard deviation of 10,000. 
```{r, tidy = TRUE}
#set the seed for reproducibility. Note, the choice of 102 was random. 
#this can be used when you are using random sampling functions to ensure the same results every time
set.seed(102)

#take a random sample of 400 values from a normal distribution with mean 100,000 and sd 10,000
DS_salary <- rnorm(n = 400, mean = 100000, sd = 10000)   

#this creates a 4 by 4 grid in which to place the following three plots
par(mfrow=c(2,2))

#plot a histogram of the salaries:  
hist(DS_salary, 
     main = "Histogram of Data Scientist's salaries", 
     cex.main = 0.7, 
     xlab = "Dollars (USD)", 
     breaks = 10)

#plot the smoothed density of the salaries: 
plot(density(DS_salary), 
     main = "Density plot of Data Scientist's salaries", 
     cex.main = 0.7, 
     xlab = "Dollars (USD)")  

#make a boxplot of the salaries: 
boxplot(DS_salary, 
        main = "Boxplot of Data Scientist's salaries", 
        cex.main = 0.7)
```

### Confidence Intervals (an example)
```{r}
#save the mean, standard deviation, and sample size
mean_ <- 100000
sd_ <- 10000
n <- 400

#note: qnorm gives quantiles for a standard normal distribition
#for example, qnorm(0.975) gives the 97.5th percentile value for a standard normal distribution
#(standard normal means mean=0 and sd=1)
error <- qnorm(0.975)*sd_/sqrt(n)
mean_ - error # lower bound of confidence interval
mean_ + error # upper bound of confidence interval
```

## Z-Tests, T-Test, and P-Values

$H_0 = \mu_{school} = \mu_{population}$
$H_a = \mu_{school} \ne \mu_{population}$

### Z-Tests and P-Values
'dnorm' : probability density function of a normal distribution \newline
'qnorm' : computes the probability from a normal distribution \newline
'pnorm' : computes the percentile from a normal distribution \newline
'rnorm' : randomly draws from a normal distribution \newline

```{r, tidy = TRUE}
# Find the proportion of sample means that are 2 points greater than or less than the state average  
# By default, pnorm gives the area under the curve of the specified normal distribution less than the
# given quantile. Therefore, if we want the area under the curve greater than that quantile, we can 
# either subtract the result from 1 or use lower.tail=FALSE to get the upper tail of the distribution 

1 - pnorm(q=72, mean = 70, sd = 1)
pnorm(q=72, mean = 70, sd = 1, lower.tail = FALSE)
```

### The t-distribution  and T-tests

Note: the t distribution is a probability distribution with a single parameter, degrees of freedom (df). It is similar to a standard normal distribution, but has heavier tails when df$<30$. When df$>30$, the t distribution is essentially identical to a standard normal distribution. In the example below we plot t-distributions with difference degrees of freedom (df = 1, 3,8, 30) and compare it to normal distribution. 

```{r}
x <- seq(-4, 4, length=100) #creates a vector of 100 equally spaced values between -4 and 4
zdist <- dnorm(x) #calculates height of a standard normal probability distribution at each value in x

degf <- c(1, 3, 8, 30) #save a vector of degrees of freedom for each t distribution
colors <- c("red", "blue", "green", "purple", "black") #save a vector of colors for the plots
labels <- c("df=1", "df=3", "df=8", "df=30", "normal") #save a vector of labels (used in legend)

plot(x=x, #give x coordinates to plot
     y=zdist, #give corresponding y coordinates
     type="l", #specify that we want a line connecting the dots
     lty=2, #make that line a little thicker (default is 1)
     xlab="Value", #give an x-axis label
     ylab="Density",  #give a y-axis label
     main="Comparison of t Distributions", #title the plot
     cex.main=0.9) #make the plot title a little smaller (default is 1)

for (i in 1:4){
  #lines() function adds lines to the plot instead of creating new plots
  lines(x=x, 
        y=dt(x=x,df=degf[i]), #now use dt() to get height of a t distribution with specified df
        lwd=2, 
        col=colors[i]) 
}

legend(x="topright",  #location for legend
       inset=.05, #add a slight inset for the legend location
       title="Distributions", #title the legend
       legend=labels, #specify text for the legend
       lwd=2, #change the size of the lines in the legend to be thicker (default is 1)
       lty=c(1, 1, 1, 1, 2), #change the line type of the lines in the legend (default is 1; dotted is 2)
       col=colors, #specify colors of the lines in the legend
       cex= 0.8) #make the legend a little smaller overall (default is 1)
```
    
  

\pagebreak
## Correlation and Covariance

We can use the 'cov' and 'cor' functions to find the covariance and correlation of two variables, respectively.  
```{r}
# Create some fake data
set.seed(102)
x <- rnorm(100)
y <- rnorm(100)
z <- x+rnorm(100,0,.4)
w <- -x+rnorm(100,0,.4)

# Calculate covariances
cov(x,z) # Positive covariance
cov(x,y) # No covariance
cov(x,w) # Negative covariance

# Calculate correlations
cor(x,z) # Positive correlation
cor(x,y) # No covariance
cor(x,w) # Negative covariance
```

\pagebreak
## Simple Ordinary Least Squares Regression   
Note: You don't need to understand how to do this yet (necessarily); however, we wanted to show you how the example from the review packet was created.  
```{r, tidy=TRUE}
# Create some fake data
set.seed(102)
child_height <- rnorm(100, 67,3)
mother_height <- child_height+rnorm(100,0,3)

# We can use lm() to fit a linear model for example lm(y~x) and store the fit
fit1 <- lm(mother_height~child_height)

plot(child_height, mother_height, pch=16, 
     main="Child height vs. Mother height",
     xlab="Mother height", ylab="Child height")
abline(fit1, col=4, lwd=2)

# The summary() function produces the summary results of fitted models 
summary(fit1)
```

